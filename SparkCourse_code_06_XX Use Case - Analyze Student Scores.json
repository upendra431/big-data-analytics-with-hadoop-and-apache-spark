{"paragraphs":[{"text":"%md \n### 6.2. Data Loading","user":"anonymous","dateUpdated":"2019-12-05T03:36:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>6.2. Data Loading</h3>\n"}]},"apps":[],"jobName":"paragraph_1575328571212_-1183710783","id":"20191202-231611_505037606","dateCreated":"2019-12-02T23:16:11+0000","dateStarted":"2019-12-05T03:36:38+0000","dateFinished":"2019-12-05T03:36:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:488"},{"text":"%md\n#### Read CSV File\n","user":"anonymous","dateUpdated":"2019-12-05T03:36:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Read CSV File</h4>\n"}]},"apps":[],"jobName":"paragraph_1575346477415_-1488209573","id":"20191203-041437_54786112","dateCreated":"2019-12-03T04:14:37+0000","dateStarted":"2019-12-05T03:36:50+0000","dateFinished":"2019-12-05T03:36:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:489"},{"text":"%spark2\n\n//Read the raw CSV file int a Spark DataFrame\nval rawStudentData = spark\n                .read\n                .option(\"inferSchema\", \"true\")\n                .option(\"header\", \"true\")\n                .csv(\"/user/raj_ops/raw_data/student_scores.csv\")\n                .withColumnRenamed(\"Class Score\",\"ClassScore\")\n                .withColumnRenamed(\"Test Score\",\"TestScore\");\n\n//Check Schema\nrawStudentData.printSchema();\n\n//Check Data\nrawStudentData.show(5)\n\n\n","user":"anonymous","dateUpdated":"2019-12-07T23:10:37+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- Student: string (nullable = true)\n |-- Subject: string (nullable = true)\n |-- ClassScore: double (nullable = true)\n |-- TestScore: double (nullable = true)\n\n+-------+---------+----------+---------+\n|Student|  Subject|ClassScore|TestScore|\n+-------+---------+----------+---------+\n|   Mike|     Math|      0.95|     2.37|\n|   Mike|Chemistry|       0.5|     1.18|\n|   Mike|  Physics|      0.48|     1.37|\n|   Mike|  Biology|      0.75|     2.79|\n|   Katy|     Math|      0.45|     1.79|\n+-------+---------+----------+---------+\nonly showing top 5 rows\n\nrawStudentData: org.apache.spark.sql.DataFrame = [Student: string, Subject: string ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1575342548979_-629450419","id":"20191203-030908_1177977425","dateCreated":"2019-12-03T03:09:08+0000","dateStarted":"2019-12-07T23:10:37+0000","dateFinished":"2019-12-07T23:10:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:490","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=9","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=10","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=11"],"interpreterSettingId":"spark2"}}},{"text":"%md\n#### Create Partitioned HDFS Store","user":"anonymous","dateUpdated":"2019-12-03T03:19:54+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Create Partitioned HDFS Store</h4>\n"}]},"apps":[],"jobName":"paragraph_1575343172293_242629332","id":"20191203-031932_1944853120","dateCreated":"2019-12-03T03:19:32+0000","dateStarted":"2019-12-03T03:19:54+0000","dateFinished":"2019-12-03T03:19:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:491"},{"text":"%spark2\n//Store CSV as Paraquet file in HDFS for better performance.\n//Partition by Subject - provides limited list of partitions\n\nrawStudentData.write\n            .format(\"parquet\")\n            .mode(\"overwrite\")\n            .option(\"compression\", \"gzip\")\n            .partitionBy(\"Subject\")\n            .save(\"/user/raj_ops/partitioned_student\")","user":"anonymous","dateUpdated":"2019-12-07T23:10:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1575343146496_-1955451588","id":"20191203-031906_685961670","dateCreated":"2019-12-03T03:19:06+0000","dateStarted":"2019-12-07T23:10:43+0000","dateFinished":"2019-12-07T23:10:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:492","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=12"],"interpreterSettingId":"spark2"}}},{"text":"%md\n#### Read partitioned data into Data Frame","user":"anonymous","dateUpdated":"2019-12-03T03:20:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Read partitioned data into Data Frame</h4>\n"}]},"apps":[],"jobName":"paragraph_1575343202105_-415225990","id":"20191203-032002_701118393","dateCreated":"2019-12-03T03:20:02+0000","dateStarted":"2019-12-03T03:20:18+0000","dateFinished":"2019-12-03T03:20:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:493"},{"text":"%spark\nval studentData = spark.read\n                    .parquet(\"/user/raj_ops/partitioned_student\")\n\nprintln(\"Partitions in student data : \" + studentData.rdd.getNumPartitions)","user":"anonymous","dateUpdated":"2019-12-07T23:20:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Partitions in student data : 2\nstudentData: org.apache.spark.sql.DataFrame = [Student: string, ClassScore: double ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1575343221717_155954857","id":"20191203-032021_1943911918","dateCreated":"2019-12-03T03:20:21+0000","dateStarted":"2019-12-07T23:20:46+0000","dateFinished":"2019-12-07T23:20:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:494","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=18"],"interpreterSettingId":"spark2"}}},{"text":"%md\n\n### 6.3. Total Score Analytics\n","user":"anonymous","dateUpdated":"2019-12-05T03:38:20+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>6.3. Total Score Analytics</h3>\n"}]},"apps":[],"jobName":"paragraph_1575517079683_-21028067","id":"20191205-033759_669527434","dateCreated":"2019-12-05T03:37:59+0000","dateStarted":"2019-12-05T03:38:20+0000","dateFinished":"2019-12-05T03:38:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:495"},{"text":"%md\n####  Compute Total Score by Student and Subject","user":"anonymous","dateUpdated":"2019-12-05T03:37:55+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Compute Total Score by Student and Subject</h4>\n"}]},"apps":[],"jobName":"paragraph_1575328668541_-683249722","id":"20191202-231748_914235504","dateCreated":"2019-12-02T23:17:48+0000","dateStarted":"2019-12-05T03:37:55+0000","dateFinished":"2019-12-05T03:37:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:496"},{"text":"%spark2\n\n//Transform / Map operation to add up columns for each row\nval totalScore = studentData.withColumn(\"TotalScore\", \n                            studentData.col(\"ClassScore\") \n                            + studentData.col(\"TestScore\"))\n                            \ntotalScore.show(5)\n\nprintln(\"-------------------------------EXPLAIN------------------------------------\")\ntotalScore.explain\nprintln(\"-------------------------------END EXPLAIN--------------------------------\\n\")","user":"anonymous","dateUpdated":"2019-12-07T23:21:36+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+----------+---------+-------+------------------+\n|Student|ClassScore|TestScore|Subject|        TotalScore|\n+-------+----------+---------+-------+------------------+\n|   Mike|      0.95|     2.37|   Math|3.3200000000000003|\n|   Katy|      0.45|     1.79|   Math|              2.24|\n|    Bob|      0.36|     2.37|   Math|              2.73|\n|   Lisa|      0.33|     2.86|   Math|              3.19|\n|   John|      0.27|      1.2|   Math|              1.47|\n+-------+----------+---------+-------+------------------+\nonly showing top 5 rows\n\n-------------------------------EXPLAIN------------------------------------\n== Physical Plan ==\n*(1) Project [Student#505, ClassScore#506, TestScore#507, Subject#508, (ClassScore#506 + TestScore#507) AS TotalScore#614]\n+- *(1) FileScan parquet [Student#505,ClassScore#506,TestScore#507,Subject#508] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://sandbox-hdp.hortonworks.com:8020/user/raj_ops/partitioned_student], PartitionCount: 4, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Student:string,ClassScore:double,TestScore:double>\n-------------------------------END EXPLAIN--------------------------------\n\ntotalScore: org.apache.spark.sql.DataFrame = [Student: string, ClassScore: double ... 3 more fields]\n"}]},"apps":[],"jobName":"paragraph_1575343391482_-1783495457","id":"20191203-032311_1452742204","dateCreated":"2019-12-03T03:23:11+0000","dateStarted":"2019-12-07T23:21:36+0000","dateFinished":"2019-12-07T23:21:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:497","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=21"],"interpreterSettingId":"spark2"}}},{"text":"%md\n#### Print Total Score for Physics for all Students\n","user":"anonymous","dateUpdated":"2019-12-05T03:37:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Print Total Score for Physics for all Students</h4>\n"}]},"apps":[],"jobName":"paragraph_1575344075099_1402340838","id":"20191203-033435_816765560","dateCreated":"2019-12-03T03:34:35+0000","dateStarted":"2019-12-05T03:37:33+0000","dateFinished":"2019-12-05T03:37:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:498"},{"text":"%spark2\n\n\n//Filter use  case. This should trigger a filter pushdown for the subject partition\nval physicsScore = totalScore.filter($\"Subject\" === \"Physics\")\n\nphysicsScore.show()\n\nprintln(\"-------------------------------EXPLAIN------------------------------------\")\nphysicsScore.explain\nprintln(\"-------------------------------END EXPLAIN--------------------------------\\n\")","user":"anonymous","dateUpdated":"2019-12-07T23:24:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+----------+---------+-------+------------------+\n|Student|ClassScore|TestScore|Subject|        TotalScore|\n+-------+----------+---------+-------+------------------+\n|   Mike|      0.48|     1.37|Physics|              1.85|\n|   Katy|      0.34|     2.72|Physics|              3.06|\n|    Bob|      0.93|     2.89|Physics|3.8200000000000003|\n|   Lisa|      0.42|     2.34|Physics|              2.76|\n|   John|      0.82|      2.8|Physics|3.6199999999999997|\n+-------+----------+---------+-------+------------------+\n\n-------------------------------EXPLAIN------------------------------------\n== Physical Plan ==\n*(1) Project [Student#251, ClassScore#252, TestScore#253, Subject#254, (ClassScore#252 + TestScore#253) AS TotalScore#260]\n+- *(1) FileScan parquet [Student#251,ClassScore#252,TestScore#253,Subject#254] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://sandbox-hdp.hortonworks.com:8020/user/raj_ops/partitioned_student], PartitionCount: 1, PartitionFilters: [isnotnull(Subject#254), (Subject#254 = Physics)], PushedFilters: [], ReadSchema: struct<Student:string,ClassScore:double,TestScore:double>\n-------------------------------END EXPLAIN--------------------------------\n\nphysicsScore: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Student: string, ClassScore: double ... 3 more fields]\n"}]},"apps":[],"jobName":"paragraph_1575344139649_-837199668","id":"20191203-033539_171289158","dateCreated":"2019-12-03T03:35:39+0000","dateStarted":"2019-12-07T23:24:38+0000","dateFinished":"2019-12-07T23:24:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:499","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=22"],"interpreterSettingId":"spark2"}}},{"text":"%md\n### 6.4. Compute Average Total Score for each student across Subjects\n","user":"anonymous","dateUpdated":"2019-12-05T03:38:37+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>6.4. Compute Average Total Score for each student across Subjects</h3>\n"}]},"apps":[],"jobName":"paragraph_1575328710879_-1385617843","id":"20191202-231830_196392886","dateCreated":"2019-12-02T23:18:30+0000","dateStarted":"2019-12-05T03:38:37+0000","dateFinished":"2019-12-05T03:38:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:500"},{"text":"%spark2\n\n//Cache the totalScore data frame so TotalScore does not get recomputed each time\ntotalScore.cache()\n\n//Group by Key operation. \nval avgScore = totalScore\n                    .groupBy(\"Student\")\n                    .avg(\"TotalScore\")\n                    \navgScore.show()\n\nprintln(\"-------------------------------EXPLAIN------------------------------------\")\navgScore.explain\nprintln(\"-------------------------------END EXPLAIN--------------------------------\\n\")\n","user":"anonymous","dateUpdated":"2019-12-07T23:32:02+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------------------+\n|Student|   avg(TotalScore)|\n+-------+------------------+\n|    Bob|             3.015|\n|   John|            2.8525|\n|   Mike|            2.5975|\n|   Lisa|2.3899999999999997|\n|   Katy|             2.455|\n+-------+------------------+\n\n-------------------------------EXPLAIN------------------------------------\n== Physical Plan ==\n*(2) HashAggregate(keys=[Student#505], functions=[avg(TotalScore#614)])\n+- Exchange hashpartitioning(Student#505, 200)\n   +- *(1) HashAggregate(keys=[Student#505], functions=[partial_avg(TotalScore#614)])\n      +- InMemoryTableScan [Student#505, TotalScore#614]\n            +- InMemoryRelation [Student#505, ClassScore#506, TestScore#507, Subject#508, TotalScore#614], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n                  +- *(1) Project [Student#505, ClassScore#506, TestScore#507, Subject#508, (ClassScore#506 + TestScore#507) AS TotalScore#614]\n                     +- *(1) FileScan parquet [Student#505,ClassScore#506,TestScore#507,Subject#508] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://sandbox-hdp.hortonworks.com:8020/user/raj_ops/partitioned_student], PartitionCount: 4, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Student:string,ClassScore:double,TestScore:double>\n-------------------------------END EXPLAIN--------------------------------\n\navgScore: org.apache.spark.sql.DataFrame = [Student: string, avg(TotalScore): double]\n"}]},"apps":[],"jobName":"paragraph_1575343700112_-2023663637","id":"20191203-032820_1691366485","dateCreated":"2019-12-03T03:28:20+0000","dateStarted":"2019-12-07T23:32:02+0000","dateFinished":"2019-12-07T23:32:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:501","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=28","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=29","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=30","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=31","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=32"],"interpreterSettingId":"spark2"}}},{"text":"%md\n###  6.5. Find Top Student by Subject\n\n\n","user":"anonymous","dateUpdated":"2019-12-05T03:38:47+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>6.5. Find Top Student by Subject</h3>\n"}]},"apps":[],"jobName":"paragraph_1575328812375_-398064937","id":"20191202-232012_79488213","dateCreated":"2019-12-02T23:20:12+0000","dateStarted":"2019-12-05T03:38:47+0000","dateFinished":"2019-12-05T03:38:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:502"},{"text":"%md\n","user":"anonymous","dateUpdated":"2019-12-07T23:43:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1575762199344_871388508","id":"20191207-234319_1148024301","dateCreated":"2019-12-07T23:43:19+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2880"},{"text":"%spark2\n\n//Find the top score for each subject\nval topScore = totalScore.groupBy(\"Subject\")\n                    .agg(max(\"TotalScore\").alias(\"TopScore\"))\n\n\ntopScore.show()\n\n//Find the student who scored the top score.\nval topStudent = totalScore.as(\"a\")\n                    .join(topScore.as(\"b\"), \n                            $\"b.TopScore\" === $\"a.TotalScore\"\n                            &&  $\"b.Subject\" === $\"a.Subject\"  )\n                    .select(\"a.Subject\",\"a.Student\",\"TopScore\")\n                    \ntopStudent.show()\n\nprintln(\"-------------------------------EXPLAIN------------------------------------\")\ntopStudent.explain\nprintln(\"-------------------------------END EXPLAIN--------------------------------\\n\")","user":"anonymous","dateUpdated":"2019-12-07T23:36:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+------------------+\n|  Subject|          TopScore|\n+---------+------------------+\n|     Math|3.3200000000000003|\n|Chemistry|3.1999999999999997|\n|  Physics|3.8200000000000003|\n|  Biology|              3.54|\n+---------+------------------+\n\n+---------+-------+------------------+\n|  Subject|Student|          TopScore|\n+---------+-------+------------------+\n|     Math|   Mike|3.3200000000000003|\n|  Physics|    Bob|3.8200000000000003|\n|Chemistry|   John|3.1999999999999997|\n|  Biology|   Mike|              3.54|\n+---------+-------+------------------+\n\n-------------------------------EXPLAIN------------------------------------\n== Physical Plan ==\n*(3) Project [Subject#508, Student#505, TopScore#836]\n+- *(3) BroadcastHashJoin [TotalScore#614, Subject#508], [TopScore#836, Subject#879], Inner, BuildRight\n   :- *(3) Filter (isnotnull(Subject#508) && isnotnull(TotalScore#614))\n   :  +- InMemoryTableScan [Student#505, Subject#508, TotalScore#614], [isnotnull(Subject#508), isnotnull(TotalScore#614)]\n   :        +- InMemoryRelation [Student#505, ClassScore#506, TestScore#507, Subject#508, TotalScore#614], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n   :              +- *(1) Project [Student#505, ClassScore#506, TestScore#507, Subject#508, (ClassScore#506 + TestScore#507) AS TotalScore#614]\n   :                 +- *(1) FileScan parquet [Student#505,ClassScore#506,TestScore#507,Subject#508] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://sandbox-hdp.hortonworks.com:8020/user/raj_ops/partitioned_student], PartitionCount: 4, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Student:string,ClassScore:double,TestScore:double>\n   +- BroadcastExchange HashedRelationBroadcastMode(List(input[1, double, false], input[0, string, true]))\n      +- *(2) Filter isnotnull(TopScore#836)\n         +- *(2) HashAggregate(keys=[Subject#879], functions=[max(TotalScore#614)])\n            +- Exchange hashpartitioning(Subject#879, 200)\n               +- *(1) HashAggregate(keys=[Subject#879], functions=[partial_max(TotalScore#614)])\n                  +- *(1) Filter isnotnull(Subject#879)\n                     +- InMemoryTableScan [Subject#879, TotalScore#614], [isnotnull(Subject#879)]\n                           +- InMemoryRelation [Student#876, ClassScore#877, TestScore#878, Subject#879, TotalScore#614], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n                                 +- *(1) Project [Student#505, ClassScore#506, TestScore#507, Subject#508, (ClassScore#506 + TestScore#507) AS TotalScore#614]\n                                    +- *(1) FileScan parquet [Student#505,ClassScore#506,TestScore#507,Subject#508] Batched: true, Format: Parquet, Location: InMemoryFileIndex[hdfs://sandbox-hdp.hortonworks.com:8020/user/raj_ops/partitioned_student], PartitionCount: 4, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Student:string,ClassScore:double,TestScore:double>\n-------------------------------END EXPLAIN--------------------------------\n\ntopScore: org.apache.spark.sql.DataFrame = [Subject: string, TopScore: double]\ntopStudent: org.apache.spark.sql.DataFrame = [Subject: string, Student: string ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1575328836294_1338899395","id":"20191202-232036_2145772318","dateCreated":"2019-12-02T23:20:36+0000","dateStarted":"2019-12-07T23:36:38+0000","dateFinished":"2019-12-07T23:36:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:503","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=33","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=34","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=35","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=36","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=37","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=38","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=39","http://sandbox-hdp.hortonworks.com:4040/jobs/job?id=40"],"interpreterSettingId":"spark2"}}},{"text":"%spark2\n","user":"anonymous","dateUpdated":"2019-12-03T03:44:04+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1575344644031_1360931571","id":"20191203-034404_1004574601","dateCreated":"2019-12-03T03:44:04+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:504"}],"name":"SparkCourse/code_06_XX Use Case - Analyze Student Scores","id":"2EWMQ5MTR","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}